{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.1 32-bit",
   "metadata": {
    "interpreter": {
     "hash": "df07b04948fcdefd07d686a15c20f5c13147995460fc283da7a7d27998f2a407"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## 1. Initialization\n",
    "\n",
    "> a. Read the excel/csv containing the entire query-output\n",
    "\n",
    "> b. Initialize the parameters of thresholds, directories, and fields to concat for generating individual as well as combined match-score\n",
    "\n",
    "> c. Get the unique list of countries in present dataframe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nUnique Countries having counts lesser than  5000 :  ['United_States']\n"
     ]
    }
   ],
   "source": [
    "import time, numpy as np, pandas as pd, re, string, subprocess #, recordlinkage\n",
    "\n",
    "_STATIC_FILE_NAME=\"SM_Temp_Shortlist.xlsx\"\n",
    "_RAW_SCORES_DIRECTORY='Raw_Scores'\n",
    "_CLEANED_SCORES_DIRECTORY='Cleaned_Scores'\n",
    "_MASTER_DATA_DIRECTORY='Master_Data'\n",
    "_FIELDS_TO_CONCAT={\n",
    "    'CONCAT_ADDRESS':   ['ADDRESS_LINE_1','ADDRESS_LINE_2','ADDRESS_LINE_3']#, 'CONCAT_SRC':       ['SITE_NAME','STATE','CITY','CONCAT_ADDRESS','POSTAL_CODE']\n",
    "                }\n",
    "\n",
    "_COLUMNS_TO_CLEAN=['ADDRESS_LINE_1','ADDRESS_LINE_2','ADDRESS_LINE_3','SITE_NAME','STATE','CITY','POSTAL_CODE']\n",
    "_BINARIES_NAME=\"levenshtein\"\n",
    "_BINARIES_EXTENSION=\".dll\"\n",
    "_MAXSIZE=5000\n",
    "\n",
    "_THRESHOLD_FOR_INDIVIDUAL=0.85\n",
    "#_THRESHOLD_FOR_ENTIRE_COMBINED=0.55\n",
    "_THRESHOLD_FOR_ADDRESS_COMBINED=0.75\n",
    "\n",
    "_THRESHOLDS_DICT={\n",
    "    'CONCAT_ADDRESS': _THRESHOLD_FOR_ADDRESS_COMBINED,\n",
    "    #'CONCAT_SRC': _THRESHOLD_FOR_ENTIRE_COMBINED, \n",
    "    'SITE_NAME': _THRESHOLD_FOR_INDIVIDUAL,\n",
    "    'STATE': _THRESHOLD_FOR_INDIVIDUAL,\n",
    "    'CITY': _THRESHOLD_FOR_INDIVIDUAL,\n",
    "    'POSTAL_CODE': _THRESHOLD_FOR_INDIVIDUAL\n",
    "    }\n",
    "_COLS_FOR_TOTAL_MATCH_CALC=[colname+'_COMPARISON_SCORE' for colname in _THRESHOLDS_DICT]\n",
    "\n",
    "_SCALING_FACTOR=3\n",
    "\n",
    "_TOTAL_MATCHES_THRESHOLD=3\n",
    "\n",
    "\n",
    "def write_df_to_csv(df, root_dir='', curr_country='', file_suffix='_temp.csv', index_flag=False):\n",
    "    try:\n",
    "        abs_path=os.path.join(root_dir, curr_country+file_suffix)\n",
    "        df.to_csv(abs_path, index=index_flag)\n",
    "        print(f'\\nSuccessfully created \\{abs_path}!')\n",
    "    except:\n",
    "        print(f'\\nSomething went wrong while writing the file. Please check if it is currently in use.')\n",
    "\n",
    "\n",
    "def preprocess_dataframe(df):\n",
    "    df.replace(np.nan, '', inplace=True)\n",
    "    for colname in df.columns.values:\n",
    "        if colname=='COUNTRY':\n",
    "            df[colname]=df[colname].apply(lambda x: x.replace(' ','_'))\n",
    "        df[colname]=df[colname].astype(str).apply(lambda x: x.strip())\n",
    "\n",
    "\n",
    "def clean_dataframe(df, replace_punctuations=True):\n",
    "    # Replaced another special character which was causing Italy CSV file read to fail in R\n",
    "    if replace_punctuations:\n",
    "        special_chars=re.escape(string.punctuation)+'\u001a'\n",
    "        print('\\nSpecial Character that will be replaced are:  ', special_chars) # !\"\\\\#\\\\$%\\\\&\\'\\\\(\\\\)\\\\*\\\\+,\\\\-\\\\./:;<=>\\\\?@\\\\[\\\\\\\\\\\\]\\\\{\\\\|\\\\}\\\\~\u001a\n",
    "    for colname in df.columns.values:\n",
    "        if colname in _COLUMNS_TO_CLEAN and replace_punctuations:\n",
    "            df[colname]=df[colname].replace(r'['+special_chars+']', '', regex=True).str.lower()\n",
    "    for colname, cols_to_concat in _FIELDS_TO_CONCAT.items():\n",
    "        df[colname]=df[cols_to_concat].apply(lambda single_row: ''.join(single_row.values), axis=1)\n",
    "    df.drop(labels=_FIELDS_TO_CONCAT['CONCAT_ADDRESS'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "def scale_up_comparison_score(df, colname='SITE_NAME_COMPARISON_SCORE', scaling_factor=_SCALING_FACTOR):\n",
    "    print(f'\\nScaling up {colname} by {scaling_factor}')\n",
    "    df[colname]=df[colname].apply(lambda x: x*scaling_factor)\n",
    "\n",
    "\n",
    "def replace_cyclic_dependencies(df, child_indicator, master_indicator):\n",
    "    arr=set(df[child_indicator].array)\n",
    "    for val in df[master_indicator]:\n",
    "        if val in arr:\n",
    "            replace_val=df[df[child_indicator]==val][master_indicator].values[0]\n",
    "            print(val,' found in normalized_duplicates[',child_indicator,']. Replacement: ', replace_val)\n",
    "            df[master_indicator].replace(val, replace_val, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def return_top_match(df, child_column, score_key_column):\n",
    "    normalized_duplicates=df.sort_values(by=[child_column]).sort_values(by=[score_key_column],ascending=False)\n",
    "    normalized_duplicates=normalized_duplicates.groupby(child_column).head(1).sort_values(by=[child_column])\n",
    "    return normalized_duplicates\n",
    "\n",
    "\n",
    "site_master_df=pd.read_excel(_STATIC_FILE_NAME, index_col=0)\n",
    "preprocess_dataframe(site_master_df)\n",
    "\n",
    "countries=list(site_master_df['COUNTRY'].unique())\n",
    "huge_countries=list(site_master_df['COUNTRY'].value_counts()[site_master_df['COUNTRY'].value_counts() > _MAXSIZE].index)\n",
    "for c in huge_countries:\n",
    "    countries.remove(c)\n",
    "\n",
    "print('\\nUnique Countries having counts lesser than ', _MAXSIZE, ': ', countries)"
   ]
  },
  {
   "source": [
    "## 2. Process data in batches: getting scores of all the candidate-pairs is highly computation intensive. RAM crashes for incoming batch-size>4000\n",
    "> a. Partition the entire input dataset based on country-name. For-loop to do the entire process for all countries.\n",
    "\n",
    "> b. Create a concatenated (address) field and drop the individual 3 address fields\n",
    "\n",
    "> c. Create a concatenated (name, address) field"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "United_States\n\nSpecial Character that will be replaced are:   !\"\\#\\$%\\&'\\(\\)\\*\\+,\\-\\./:;<=>\\?@\\[\\\\\\]\\^_`\\{\\|\\}\\~\u001a\n\nSuccessfully created \\United_States_country_df.csv!\n\nUnited_States has 1000 records\n"
     ]
    }
   ],
   "source": [
    "# todo: for loop- Research on multithreading to speed up country-wise batches. RAM might crash for incoming batch-size>4000.\n",
    "\n",
    "c=0\n",
    "curr_country=countries[c]\n",
    "country_df=site_master_df[site_master_df['COUNTRY']==curr_country]\n",
    "print(curr_country)\n",
    "clean_dataframe(country_df)\n",
    "write_df_to_csv(df=country_df[_THRESHOLDS_DICT.keys()], curr_country=curr_country, file_suffix='_country_df.csv', index_flag=True)\n",
    "\n",
    "# todo: Imputation of address values where Site-name is exactly the same, otherwise it'll result in 2 separate master-records\n",
    "\n",
    "print(f'\\n{curr_country} has {country_df.shape[0]} records')"
   ]
  },
  {
   "source": [
    "## 3. Initialize the candidate-pairs for comparison via the Index() object, and a Comparer() object with set of fields to compare amongst the candidate pairs\n",
    "\n",
    "### Currently configured to run this match-score generation in R, such that:\n",
    "\n",
    "> if individual fields' match-score > 85% , then set the *_col_*_COMPARISON_SCORE column to 1, else 0\n",
    "\n",
    "> if combined address-fields' match-score > 75% , then set the CONCAT_ADDRESS_COMPARISON_SCORE column to 1, else 0\n",
    "\n",
    "### Comparer algorithm can be: 'jaro', 'jarowinkler', 'levenshtein', 'damerau_levenshtein', 'qgram', 'cosine', 'smith_waterman', 'lcs'\n",
    "\n",
    "### You can also set n_job=-1 to use up all cores available for parallel-computation of scores for the candidate-pairs."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "R OUTPUT:\n [1] \"levenshtein .dll 0.85 0.75 3 United_States Raw_Scores 3\"\n[1] \"NRows= 1000 , Candidate-pairs= 499500 , Columns are \"\n[1] \"SR_NUM\"         \"CONCAT_ADDRESS\" \"SITE_NAME\"      \"STATE\"         \n[5] \"CITY\"           \"POSTAL_CODE\"   \n[1] \"Loading levenshtein.dll !\"\n[1] 4000\n         used (Mb) gc trigger (Mb) max used (Mb)\nNcells 126771  3.4     350000  9.4   313569  8.4\nVcells 176765  1.4     786432  6.0   784755  6.0\n[1] \"NRows= 499500 , Columns are \"\n[1] \"id1\"            \"id2\"            \"CONCAT_ADDRESS\" \"SITE_NAME\"     \n[5] \"STATE\"          \"CITY\"           \"POSTAL_CODE\"    \"is_match\"      \n[1] \"SITE_NAME  :  0.85\"\n[1] \"STATE  :  0.85\"\n[1] \"CITY  :  0.85\"\n[1] \"POSTAL_CODE  :  0.85\"\n[1] \"CONCAT_ADDRESS  :  0.75\"\nTime difference of 17.24558 secs\n[1] \"Raw_Scores//United_States_Score_Features.csv\"\n[1] \"Successfully created //Raw_Scores//United_States_Score_Features.csv !\"\n\n"
     ]
    }
   ],
   "source": [
    "# todo: invoke the R-code from Python using 32-bit Rscript 3.4.4 command\n",
    "from subprocess import Popen, PIPE\n",
    "\n",
    "pipe = Popen(\n",
    "    [\n",
    "    \"C:/Program Files/R/R-3.4.4/bin/i386/Rscript\", \"Site_Master_Record_Linkage.R\",\n",
    "    f\"{_BINARIES_NAME} {_BINARIES_EXTENSION} {_THRESHOLD_FOR_INDIVIDUAL} {_THRESHOLD_FOR_ADDRESS_COMBINED} {_SCALING_FACTOR} {curr_country} {_RAW_SCORES_DIRECTORY} {_TOTAL_MATCHES_THRESHOLD}\"\n",
    "    ],\n",
    "    cwd=\"C:/Users/vdeshpande/Desktop/Del_Project-Takeda/Site_Master_Repo/\",\n",
    "    stdin=PIPE, stdout=PIPE, stderr=PIPE,shell=True\n",
    "    )\n",
    "\n",
    "output, error = pipe.communicate()\n",
    "\n",
    "# Print R-console output\n",
    "if pipe.returncode == 0:            \n",
    "    print('R OUTPUT:\\n',output.decode())\n",
    "else:\n",
    "    print('R OUTPUT:\\n',output.decode())\n",
    "    print('R ERROR:\\n',error.decode())"
   ]
  },
  {
   "source": [
    "## 4. Get the set of potential duplicates where TOTAL_SCORE > THRESHOLD\n",
    "\n",
    "### Currently configured to perform this in R itself.\n",
    "\n",
    "> R code will finally generate the *Country*_Score_Features.csv in the /Raw_Scores/ directory"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "duplicates=pd.read_csv(os.path.join(_RAW_SCORES_DIRECTORY, curr_country+'_Score_Features.csv'))\n",
    "duplicates['COUNTRY']=curr_country\n",
    "duplicates.head(30)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    SR_NUM_1  SR_NUM_2  SITE_NAME_COMPARISON_SCORE  STATE_COMPARISON_SCORE  \\\n",
       "0          3         1                           1                       1   \n",
       "1        154         1                           1                       1   \n",
       "2        234         1                           1                       1   \n",
       "3        235         1                           1                       1   \n",
       "4        277         1                           1                       1   \n",
       "5        278         1                           1                       1   \n",
       "6        316         1                           1                       1   \n",
       "7        317         1                           1                       1   \n",
       "8        319         1                           1                       1   \n",
       "9         41         2                           1                       1   \n",
       "10       141         2                           1                       1   \n",
       "11       153         2                           1                       1   \n",
       "12       318         2                           1                       1   \n",
       "13       154         3                           1                       1   \n",
       "14       234         3                           1                       1   \n",
       "15       235         3                           1                       1   \n",
       "16       277         3                           1                       1   \n",
       "17       278         3                           1                       1   \n",
       "18       316         3                           1                       1   \n",
       "19       317         3                           1                       1   \n",
       "20       319         3                           1                       1   \n",
       "21        44         5                           0                       1   \n",
       "22       245         5                           0                       1   \n",
       "23       246         5                           0                       1   \n",
       "24       146         6                           0                       1   \n",
       "25       247         6                           0                       1   \n",
       "26       323         6                           0                       1   \n",
       "27       325         6                           1                       1   \n",
       "28       326         6                           0                       1   \n",
       "29       364         6                           1                       1   \n",
       "\n",
       "    CITY_COMPARISON_SCORE  POSTAL_CODE_COMPARISON_SCORE  \\\n",
       "0                       1                             1   \n",
       "1                       1                             1   \n",
       "2                       1                             1   \n",
       "3                       1                             1   \n",
       "4                       1                             1   \n",
       "5                       1                             1   \n",
       "6                       1                             1   \n",
       "7                       1                             1   \n",
       "8                       1                             1   \n",
       "9                       1                             1   \n",
       "10                      1                             1   \n",
       "11                      1                             1   \n",
       "12                      1                             1   \n",
       "13                      1                             1   \n",
       "14                      1                             1   \n",
       "15                      1                             1   \n",
       "16                      1                             1   \n",
       "17                      1                             1   \n",
       "18                      1                             1   \n",
       "19                      1                             1   \n",
       "20                      1                             1   \n",
       "21                      1                             1   \n",
       "22                      1                             1   \n",
       "23                      1                             1   \n",
       "24                      1                             1   \n",
       "25                      1                             1   \n",
       "26                      1                             0   \n",
       "27                      1                             1   \n",
       "28                      1                             1   \n",
       "29                      1                             1   \n",
       "\n",
       "    CONCAT_ADDRESS_COMPARISON_SCORE  NUM_OF_MATCHES_FOUND        COUNTRY  \n",
       "0                                 3                     7  United_States  \n",
       "1                                 3                     7  United_States  \n",
       "2                                 3                     7  United_States  \n",
       "3                                 3                     7  United_States  \n",
       "4                                 3                     7  United_States  \n",
       "5                                 3                     7  United_States  \n",
       "6                                 3                     7  United_States  \n",
       "7                                 3                     7  United_States  \n",
       "8                                 3                     7  United_States  \n",
       "9                                 3                     7  United_States  \n",
       "10                                3                     7  United_States  \n",
       "11                                3                     7  United_States  \n",
       "12                                3                     7  United_States  \n",
       "13                                3                     7  United_States  \n",
       "14                                3                     7  United_States  \n",
       "15                                3                     7  United_States  \n",
       "16                                3                     7  United_States  \n",
       "17                                3                     7  United_States  \n",
       "18                                3                     7  United_States  \n",
       "19                                3                     7  United_States  \n",
       "20                                3                     7  United_States  \n",
       "21                                3                     6  United_States  \n",
       "22                                3                     6  United_States  \n",
       "23                                3                     6  United_States  \n",
       "24                                3                     6  United_States  \n",
       "25                                3                     6  United_States  \n",
       "26                                3                     5  United_States  \n",
       "27                                3                     7  United_States  \n",
       "28                                3                     6  United_States  \n",
       "29                                0                     4  United_States  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SR_NUM_1</th>\n      <th>SR_NUM_2</th>\n      <th>SITE_NAME_COMPARISON_SCORE</th>\n      <th>STATE_COMPARISON_SCORE</th>\n      <th>CITY_COMPARISON_SCORE</th>\n      <th>POSTAL_CODE_COMPARISON_SCORE</th>\n      <th>CONCAT_ADDRESS_COMPARISON_SCORE</th>\n      <th>NUM_OF_MATCHES_FOUND</th>\n      <th>COUNTRY</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>154</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>234</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>235</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>277</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>278</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>316</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>317</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>319</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>41</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>141</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>153</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>318</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>154</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>234</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>235</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>277</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>278</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>316</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>317</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>319</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>44</td>\n      <td>5</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>6</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>245</td>\n      <td>5</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>6</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>246</td>\n      <td>5</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>6</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>146</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>6</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>247</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>6</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>323</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>5</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>325</td>\n      <td>6</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>326</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>6</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>364</td>\n      <td>6</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n      <td>United_States</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ]
  },
  {
   "source": [
    "## 5. Choose the best match for incoming child records based on highest total-score"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     SR_NUM_1  SR_NUM_2  SITE_NAME_COMPARISON_SCORE  STATE_COMPARISON_SCORE  \\\n",
       "0           3         1                           1                       1   \n",
       "57         30        29                           1                       1   \n",
       "46         34        24                           0                       0   \n",
       "9          41         2                           1                       1   \n",
       "21         44         5                           0                       1   \n",
       "67         54        33                           0                       1   \n",
       "115        57        56                           0                       1   \n",
       "111        59        54                           0                       1   \n",
       "118        61        58                           0                       1   \n",
       "55         63        28                           1                       1   \n",
       "125        67        62                           0                       1   \n",
       "43         68        22                           0                       1   \n",
       "134        73        72                           1                       1   \n",
       "77         74        38                           0                       1   \n",
       "143        79        78                           0                       1   \n",
       "154        89        88                           0                       1   \n",
       "155        91        90                           1                       1   \n",
       "156        92        90                           1                       1   \n",
       "161        94        93                           1                       1   \n",
       "162        97        96                           1                       1   \n",
       "163       100        96                           1                       1   \n",
       "179       108       106                           0                       1   \n",
       "82        111        40                           1                       0   \n",
       "195       113       112                           0                       1   \n",
       "186       124       111                           1                       0   \n",
       "180       133       106                           0                       1   \n",
       "187       137       111                           1                       0   \n",
       "92        141        41                           1                       1   \n",
       "24        146         6                           0                       1   \n",
       "93        153        41                           1                       1   \n",
       "\n",
       "     CITY_COMPARISON_SCORE  POSTAL_CODE_COMPARISON_SCORE  \\\n",
       "0                        1                             1   \n",
       "57                       1                             1   \n",
       "46                       1                             0   \n",
       "9                        1                             1   \n",
       "21                       1                             1   \n",
       "67                       1                             1   \n",
       "115                      1                             1   \n",
       "111                      1                             1   \n",
       "118                      0                             1   \n",
       "55                       1                             0   \n",
       "125                      1                             0   \n",
       "43                       1                             1   \n",
       "134                      1                             1   \n",
       "77                       1                             1   \n",
       "143                      1                             0   \n",
       "154                      1                             1   \n",
       "155                      1                             1   \n",
       "156                      1                             1   \n",
       "161                      1                             1   \n",
       "162                      1                             1   \n",
       "163                      1                             1   \n",
       "179                      1                             1   \n",
       "82                       0                             0   \n",
       "195                      1                             1   \n",
       "186                      0                             0   \n",
       "180                      1                             1   \n",
       "187                      0                             0   \n",
       "92                       1                             1   \n",
       "24                       1                             1   \n",
       "93                       1                             1   \n",
       "\n",
       "     CONCAT_ADDRESS_COMPARISON_SCORE  NUM_OF_MATCHES_FOUND        COUNTRY  \n",
       "0                                  3                     7  United_States  \n",
       "57                                 3                     7  United_States  \n",
       "46                                 3                     4  United_States  \n",
       "9                                  3                     7  United_States  \n",
       "21                                 3                     6  United_States  \n",
       "67                                 3                     6  United_States  \n",
       "115                                3                     6  United_States  \n",
       "111                                3                     6  United_States  \n",
       "118                                3                     5  United_States  \n",
       "55                                 3                     6  United_States  \n",
       "125                                3                     5  United_States  \n",
       "43                                 3                     6  United_States  \n",
       "134                                3                     7  United_States  \n",
       "77                                 3                     6  United_States  \n",
       "143                                3                     5  United_States  \n",
       "154                                3                     6  United_States  \n",
       "155                                0                     4  United_States  \n",
       "156                                0                     4  United_States  \n",
       "161                                3                     7  United_States  \n",
       "162                                0                     4  United_States  \n",
       "163                                3                     7  United_States  \n",
       "179                                3                     6  United_States  \n",
       "82                                 3                     4  United_States  \n",
       "195                                3                     6  United_States  \n",
       "186                                3                     4  United_States  \n",
       "180                                3                     6  United_States  \n",
       "187                                3                     4  United_States  \n",
       "92                                 3                     7  United_States  \n",
       "24                                 3                     6  United_States  \n",
       "93                                 3                     7  United_States  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SR_NUM_1</th>\n      <th>SR_NUM_2</th>\n      <th>SITE_NAME_COMPARISON_SCORE</th>\n      <th>STATE_COMPARISON_SCORE</th>\n      <th>CITY_COMPARISON_SCORE</th>\n      <th>POSTAL_CODE_COMPARISON_SCORE</th>\n      <th>CONCAT_ADDRESS_COMPARISON_SCORE</th>\n      <th>NUM_OF_MATCHES_FOUND</th>\n      <th>COUNTRY</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>30</td>\n      <td>29</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>34</td>\n      <td>24</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>4</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>41</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>44</td>\n      <td>5</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>6</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>54</td>\n      <td>33</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>6</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>115</th>\n      <td>57</td>\n      <td>56</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>6</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>111</th>\n      <td>59</td>\n      <td>54</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>6</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>118</th>\n      <td>61</td>\n      <td>58</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>5</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>63</td>\n      <td>28</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>6</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>125</th>\n      <td>67</td>\n      <td>62</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>5</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>68</td>\n      <td>22</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>6</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>134</th>\n      <td>73</td>\n      <td>72</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td>74</td>\n      <td>38</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>6</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>143</th>\n      <td>79</td>\n      <td>78</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>5</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>154</th>\n      <td>89</td>\n      <td>88</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>6</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>155</th>\n      <td>91</td>\n      <td>90</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>156</th>\n      <td>92</td>\n      <td>90</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>161</th>\n      <td>94</td>\n      <td>93</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>162</th>\n      <td>97</td>\n      <td>96</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>163</th>\n      <td>100</td>\n      <td>96</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>179</th>\n      <td>108</td>\n      <td>106</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>6</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>111</td>\n      <td>40</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>4</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>113</td>\n      <td>112</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>6</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>186</th>\n      <td>124</td>\n      <td>111</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>4</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>180</th>\n      <td>133</td>\n      <td>106</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>6</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>187</th>\n      <td>137</td>\n      <td>111</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>4</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>92</th>\n      <td>141</td>\n      <td>41</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>146</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>6</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>93</th>\n      <td>153</td>\n      <td>41</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>United_States</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "normalized_duplicates=return_top_match(df=duplicates, child_column='SR_NUM_1', score_key_column='NUM_OF_MATCHES_FOUND')\n",
    "normalized_duplicates.head(30)"
   ]
  },
  {
   "source": [
    "## 5. Reusable function to replace the cyclic matches\n",
    "### For example:\n",
    "\n",
    ">   Record45 matches with Record44\n",
    "\n",
    ">   Record67 matches with Record45\n",
    "\n",
    "### In this case we should maintain:\n",
    ">   Record67 matches with Record44"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "54  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  33\n",
      "111  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  40\n",
      "41  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  2\n",
      "155  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  42\n",
      "30  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  29\n",
      "183  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  33\n",
      "192  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  86\n",
      "208  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  96\n",
      "137  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  40\n",
      "61  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  58\n",
      "154  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  1\n",
      "3  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  1\n",
      "170  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  42\n",
      "158  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  148\n",
      "44  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  5\n",
      "189  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  26\n",
      "191  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  138\n",
      "220  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  40\n",
      "234  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  1\n",
      "239  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  42\n",
      "280  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  135\n",
      "67  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  62\n",
      "74  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  38\n",
      "153  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  2\n",
      "277  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  1\n",
      "247  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  6\n",
      "325  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  6\n",
      "34  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  24\n",
      "216  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  50\n",
      "225  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  114\n",
      "229  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  58\n",
      "205  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  103\n",
      "97  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  96\n",
      "543  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  172\n",
      "184  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  33\n",
      "286  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  16\n",
      "301  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  62\n",
      "63  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  28\n",
      "233  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  132\n",
      "255  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  26\n",
      "561  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  26\n",
      "256  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  138\n",
      "589  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  262\n",
      "263  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  40\n",
      "373  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  276\n",
      "361  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  271\n",
      "285  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  10\n",
      "223  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  80\n",
      "92  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  90\n",
      "822  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  80\n",
      "213  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  212\n",
      "73  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  72\n",
      "556  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  33\n",
      "846  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  160\n",
      "237  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  142\n",
      "353  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  40\n",
      "399  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  87\n",
      "68  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  22\n",
      "258  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  138\n",
      "133  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  106\n",
      "850  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  16\n",
      "304  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  29\n",
      "566  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  26\n",
      "113  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  112\n",
      "930  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  123\n",
      "988  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  854\n",
      "847  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  160\n",
      "875  found in normalized_duplicates[ SR_NUM_1 ]. Replacement:  865\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     SR_NUM_1  SR_NUM_2  SITE_NAME_COMPARISON_SCORE  STATE_COMPARISON_SCORE  \\\n",
       "0           3         1                           1                       1   \n",
       "57         30        29                           1                       1   \n",
       "46         34        24                           0                       0   \n",
       "9          41         2                           1                       1   \n",
       "21         44         5                           0                       1   \n",
       "..        ...       ...                         ...                     ...   \n",
       "273       995       160                           1                       1   \n",
       "316       996       201                           1                       1   \n",
       "149       998        83                           1                       1   \n",
       "539       999       865                           1                       1   \n",
       "540      1000       865                           1                       1   \n",
       "\n",
       "     CITY_COMPARISON_SCORE  POSTAL_CODE_COMPARISON_SCORE  \\\n",
       "0                        1                             1   \n",
       "57                       1                             1   \n",
       "46                       1                             0   \n",
       "9                        1                             1   \n",
       "21                       1                             1   \n",
       "..                     ...                           ...   \n",
       "273                      1                             1   \n",
       "316                      1                             1   \n",
       "149                      1                             1   \n",
       "539                      1                             0   \n",
       "540                      1                             1   \n",
       "\n",
       "     CONCAT_ADDRESS_COMPARISON_SCORE  NUM_OF_MATCHES_FOUND        COUNTRY  \n",
       "0                                  3                     7  United_States  \n",
       "57                                 3                     7  United_States  \n",
       "46                                 3                     4  United_States  \n",
       "9                                  3                     7  United_States  \n",
       "21                                 3                     6  United_States  \n",
       "..                               ...                   ...            ...  \n",
       "273                                3                     7  United_States  \n",
       "316                                0                     4  United_States  \n",
       "149                                3                     7  United_States  \n",
       "539                                3                     6  United_States  \n",
       "540                                3                     7  United_States  \n",
       "\n",
       "[247 rows x 9 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SR_NUM_1</th>\n      <th>SR_NUM_2</th>\n      <th>SITE_NAME_COMPARISON_SCORE</th>\n      <th>STATE_COMPARISON_SCORE</th>\n      <th>CITY_COMPARISON_SCORE</th>\n      <th>POSTAL_CODE_COMPARISON_SCORE</th>\n      <th>CONCAT_ADDRESS_COMPARISON_SCORE</th>\n      <th>NUM_OF_MATCHES_FOUND</th>\n      <th>COUNTRY</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>30</td>\n      <td>29</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>34</td>\n      <td>24</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>4</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>41</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>44</td>\n      <td>5</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>6</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>273</th>\n      <td>995</td>\n      <td>160</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>316</th>\n      <td>996</td>\n      <td>201</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>998</td>\n      <td>83</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>539</th>\n      <td>999</td>\n      <td>865</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>6</td>\n      <td>United_States</td>\n    </tr>\n    <tr>\n      <th>540</th>\n      <td>1000</td>\n      <td>865</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>United_States</td>\n    </tr>\n  </tbody>\n</table>\n<p>247 rows × 9 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "normalized_duplicates=replace_cyclic_dependencies(df=normalized_duplicates, child_indicator='SR_NUM_1', master_indicator='SR_NUM_2')\n",
    "normalized_duplicates"
   ]
  },
  {
   "source": [
    "## 6. CSV for static-analysis of matches"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nSuccessfully created \\Cleaned_Scores\\United_States_Cleaned_Feature_Scores.csv!\n\n\"SR_NUM_2\" will be the master record\n"
     ]
    }
   ],
   "source": [
    "write_df_to_csv(df=normalized_duplicates, root_dir=_CLEANED_SCORES_DIRECTORY, curr_country=curr_country, file_suffix='_Cleaned_Feature_Scores.csv')\n",
    "print('\\n\"SR_NUM_2\" will be the master record')"
   ]
  },
  {
   "source": [
    "## 7. Get the unique set of Master-Records and create a master CSV file for each country\n",
    "\n",
    "> a. Think of 'SR_NUM_1' as the list of incoming Primary-keys, and 'SR_NUM_2' as the value to which it should be mapped based on match-score\n",
    "\n",
    "> b. Hence, union of 'SR_NUM_1' & 'SR_NUM_2' will be entire set of duplicates\n",
    "\n",
    "> c. Stand-alone records in the current country_batch_dataframe will not fall in this entire set of duplicates\n",
    "\n",
    "> d. Master-records set wil be the sets of 'SR_NUM_2' & #c above."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1000 records get merged into 753\n\nSuccessfully created \\Master_Data\\United_States_Master.csv!\n"
     ]
    }
   ],
   "source": [
    "a1=set(normalized_duplicates['SR_NUM_1'].values.tolist())\n",
    "a2=set(normalized_duplicates['SR_NUM_2'].values.tolist())\n",
    "country_set=set(country_df.index.values.tolist())\n",
    "entire_duplicates_set=a1.union(a2)\n",
    "no_match_set=country_set.difference(entire_duplicates_set)\n",
    "master_record_ids=no_match_set.union(a2)\n",
    "\n",
    "\n",
    "\n",
    "country_df_copy=site_master_df[site_master_df['COUNTRY']==curr_country]\n",
    "preprocess_dataframe(df=country_df_copy)\n",
    "clean_dataframe(df=country_df_copy, replace_punctuations=False)\n",
    "\n",
    "print(f'{site_master_df.shape[0]} records get merged into {len(master_record_ids)}')\n",
    "#country_master_df=country_df_copy.loc[master_record_ids].drop('CONCAT_SRC',axis=1)\n",
    "country_master_df=country_df_copy.loc[master_record_ids]\n",
    "write_df_to_csv(df=country_master_df, root_dir=_MASTER_DATA_DIRECTORY, curr_country=curr_country, index_flag=True, file_suffix='_Master.csv')"
   ]
  },
  {
   "source": [
    "## 8. Get the normalized-duplicates into a CSV to show translation of incoming record into single golden record\n",
    "\n",
    "> a. Create a master_cross_reference_df for the master_record_ids with relevant scores scaled up by _SCALING_FACTOR, and other comparison scores set to 1\n",
    "\n",
    "> b. concat it with the normalized_duplicates dataframe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nScaling up CONCAT_ADDRESS_COMPARISON_SCORE by 3\n\nSuccessfully created \\Master_Data\\United_States_Raw_Cross_Ref.csv!\n"
     ]
    }
   ],
   "source": [
    "master_record_score_array=[1.0]*len(master_record_ids)\n",
    "master_record_df_dict={\n",
    "    'SR_NUM_1': list(master_record_ids),\n",
    "    'SR_NUM_2': list(master_record_ids),\n",
    "    'SITE_NAME_COMPARISON_SCORE': master_record_score_array,\n",
    "    'STATE_COMPARISON_SCORE': master_record_score_array,\n",
    "    'CITY_COMPARISON_SCORE': master_record_score_array,\n",
    "    'CONCAT_ADDRESS_COMPARISON_SCORE': master_record_score_array,\n",
    "    'POSTAL_CODE_COMPARISON_SCORE': master_record_score_array }\n",
    "\n",
    "cross_ref_df=pd.DataFrame(master_record_df_dict)\n",
    "cross_ref_df['COUNTRY']=curr_country\n",
    "scale_up_comparison_score(cross_ref_df,'CONCAT_ADDRESS_COMPARISON_SCORE',_SCALING_FACTOR)\n",
    "cross_ref_df['NUM_OF_MATCHES_FOUND']=cross_ref_df[_COLS_FOR_TOTAL_MATCH_CALC].sum(axis=1)\n",
    "\n",
    "\n",
    "cross_ref_df=cross_ref_df.append(normalized_duplicates)\n",
    "cross_ref_df.sort_values(by=['SR_NUM_1'], axis=0, inplace=True)\n",
    "\n",
    "write_df_to_csv(df=cross_ref_df, root_dir=_MASTER_DATA_DIRECTORY, curr_country=curr_country, file_suffix='_Raw_Cross_Ref.csv')"
   ]
  },
  {
   "source": [
    "## 9. Generate the report to display name & address fields of match-and-merge combinations\n",
    "\n",
    "> a. Merge the master_cross_reference_df with the country_batch_dataframe as a left-outer-join on Primary-key='SR_NUM_1'\n",
    "\n",
    "> b. Merge this master_cross_reference_df with the country_batch_dataframe as a left-outer-join on Primary-key='SR_NUM_2'"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nSuccessfully created \\Master_Data\\United_States_Cross_Ref_Full_Report.csv!\n"
     ]
    }
   ],
   "source": [
    "country_df_copy.reset_index(inplace=True)\n",
    "country_df_colnames=country_df_copy.columns.values\n",
    "\n",
    "country_df_copy.columns=[colname+'_1' for colname in country_df_colnames]\n",
    "cross_ref_df=cross_ref_df.merge(country_df_copy, how='left', on='SR_NUM_1')\n",
    "\n",
    "country_df_copy.columns=[colname+'_2' for colname in country_df_colnames]\n",
    "cross_ref_df=cross_ref_df.merge(country_df_copy, how='left', on='SR_NUM_2')\n",
    "cross_ref_df=cross_ref_df[['SR_NUM_1', 'SR_NUM_2', 'SITE_NAME_1','SITE_NAME_2','SITE_NAME_COMPARISON_SCORE','STATE_1','STATE_2','STATE_COMPARISON_SCORE', 'CITY_1','CITY_2','CITY_COMPARISON_SCORE','CONCAT_ADDRESS_1','CONCAT_ADDRESS_2','CONCAT_ADDRESS_COMPARISON_SCORE', 'POSTAL_CODE_1','POSTAL_CODE_2','POSTAL_CODE_COMPARISON_SCORE','NUM_OF_MATCHES_FOUND']]\n",
    "\n",
    "write_df_to_csv(df=cross_ref_df, root_dir=_MASTER_DATA_DIRECTORY, curr_country=curr_country, file_suffix='_Cross_Ref_Full_Report.csv')"
   ]
  }
 ]
}